

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Disagreement sampling for committee-based sampling &mdash; modAL  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Pool-based sampling" href="../examples/Pool-based-sampling.html" />
    <link rel="prev" title="Uncertainty sampling" href="Uncertainty-sampling.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/modAL_b.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/modAL-in-a-nutshell.html">modAL in a nutshell</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/Installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overview/Extending-modAL.html">Extending modAL</a></li>
</ul>
<p class="caption"><span class="caption-text">Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/ActiveLearner.html">ActiveLearner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/BayesianOptimizer.html">BayesianOptimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/Committee.html">Committee</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/CommitteeRegressor.html">CommitteeRegressor</a></li>
</ul>
<p class="caption"><span class="caption-text">Query strategies</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Acquisition-functions.html">Acquisition functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="Uncertainty-sampling.html">Uncertainty sampling</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Disagreement sampling</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#disagreement-sampling-for-classifiers">Disagreement sampling for classifiers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#vote-entropy">Vote entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#consensus-entropy">Consensus entropy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#max-disagreement">Max disagreement</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#disagreement-sampling-for-regressors">Disagreement sampling for regressors</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#standard-deviation-sampling">Standard deviation sampling</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#disagreement-measures-in-action">Disagreement measures in action</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../examples/Pool-based-sampling.html">Pool-based sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Stream-based-sampling.html">Stream-based sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Active-regression.html">Active regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Ensemble-regression.html">Ensemble regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Bayesian-optimization.html">Bayesian optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Query-by-committee.html">Query by committee</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Bootstrapping-and-bagging.html">Bootstrapping and bagging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/Keras-integration.html">Keras integration</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">modAL</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Disagreement sampling for committee-based sampling</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/content/query_strategies/Disagreement-sampling.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="disagreement-sampling-for-committee-based-sampling">
<h1>Disagreement sampling for committee-based sampling<a class="headerlink" href="#disagreement-sampling-for-committee-based-sampling" title="Permalink to this headline">¶</a></h1>
<p>When you have several hypothesis about your data, selecting the next instances to label can be done by measuring the disagreement between the hypotheses. Naturally, there are many ways to do that. In modAL, there are three built-in disagreement measures and query strategies: <em>vote entropy</em>, <em>consensus entropy</em> and <em>maximum disagreement</em>. In this quick tutorial, we are going to review them. For more details, see Section 3.4 of the awesome book <a class="reference external" href="http://active-learning.net/">Active learning by Burr Settles</a>.</p>
<div class="section" id="disagreement-sampling-for-classifiers">
<h2>Disagreement sampling for classifiers<a class="headerlink" href="#disagreement-sampling-for-classifiers" title="Permalink to this headline">¶</a></h2>
<p>Committee-based models in modAL come in two flavors: Committee for classifiers and CommitteeRegressor for regressors. First, let’s take a look at disagreement-based sampling strategies for classification!</p>
<div class="section" id="vote-entropy">
<h3>Vote entropy<a class="headerlink" href="#vote-entropy" title="Permalink to this headline">¶</a></h3>
<p>Suppose that you have a Committee of three classifiers, classes <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2]</span></code> and five instances to classify. If you would like to
calculate the vote entropy, first you ask every classifier about its prediction:</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vote</span>
<span class="gp">... </span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]]</span>
</pre></div>
</div>
<p>Each instance has a corresponding probability distribution to it: the distribution of class labels when picking a classifier by random. In the first instance, there are two votes for <code class="docutils literal notranslate"><span class="pre">0</span></code>, one votes for <code class="docutils literal notranslate"><span class="pre">1</span></code> and zero votes for <code class="docutils literal notranslate"><span class="pre">2</span></code>. In this case, this distribution is <code class="docutils literal notranslate"><span class="pre">[0.6666,</span> <span class="pre">0.3333,</span> <span class="pre">0.0]</span></code>. The distributions for all instances are</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">p_vote</span>
<span class="gp">... </span><span class="p">[[</span><span class="mf">0.6666</span><span class="p">,</span> <span class="mf">0.3333</span><span class="p">,</span> <span class="mf">0.0</span>   <span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.0</span>   <span class="p">,</span> <span class="mf">0.6666</span><span class="p">,</span> <span class="mf">0.3333</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.3333</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span><span class="mi">3333</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span><span class="mi">3333</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.0</span>   <span class="p">,</span> <span class="mf">0.0</span>   <span class="p">,</span> <span class="mf">1.0</span>   <span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.0</span>   <span class="p">,</span> <span class="mf">0.3333</span><span class="p">,</span> <span class="mf">0.6666</span><span class="p">]]</span>
</pre></div>
</div>
<p>Vote entropy selects the instance for which the entropy of this vote distribution is the largest. In this case, the vote entropies are</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vote_entropy</span>
<span class="gp">... </span><span class="p">[</span><span class="mf">0.6365</span><span class="p">,</span> <span class="mf">0.6365</span><span class="p">,</span> <span class="mf">1.0986</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6365</span><span class="p">]</span>
</pre></div>
</div>
<p>Since all three votes are different for the third instance, the entropy is the largest there, thus a vote entropy based query strategy would choose that one.</p>
</div>
<div class="section" id="consensus-entropy">
<h3>Consensus entropy<a class="headerlink" href="#consensus-entropy" title="Permalink to this headline">¶</a></h3>
<p>Instead of calculating the distribution of the votes, the <em>consensus
entropy</em> disagreement measure first calculates the average of the class
probabilities of each classifier. This is called the consensus
probability. Then the entropy of the consensus probability is calculated
and the instance with largest consensus entropy is selected.</p>
<p>For an example, let’s suppose that we continue the previous example with
three classifiers, classes <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">2]</span></code> and five instances to classify.
For each classifier, the class probabilities are</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">vote_proba</span>
<span class="gp">... </span><span class="p">[[[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>    <span class="c1"># \</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>    <span class="c1"># |</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>    <span class="c1"># |  &lt;-- class probabilities for the first classifier</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>    <span class="c1"># |</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span>  <span class="c1"># /</span>
<span class="gp">... </span> <span class="p">[[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>    <span class="c1"># \</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>    <span class="c1"># |</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>    <span class="c1"># |  &lt;-- class probabilities for the second classifier</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>    <span class="c1"># |</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">]],</span>  <span class="c1"># /</span>
<span class="gp">... </span> <span class="p">[[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>    <span class="c1"># \</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]</span>    <span class="c1"># |</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>    <span class="c1"># |  &lt;-- class probabilities for the third classifier</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>    <span class="c1"># |</span>
<span class="gp">... </span>  <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]]]</span>  <span class="c1"># /</span>
</pre></div>
</div>
<p>In this case, the consensus probabilities are</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">consensus_proba</span>
<span class="gp">... </span><span class="p">[[</span><span class="mf">0.5</span>   <span class="p">,</span> <span class="mf">0.4333</span><span class="p">,</span> <span class="mf">0.0333</span><span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.3666</span><span class="p">,</span> <span class="mf">0.4333</span><span class="p">,</span> <span class="mf">0.2</span>   <span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.5</span>   <span class="p">,</span> <span class="mf">0.3</span>   <span class="p">,</span> <span class="mf">0.2</span>   <span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.2</span>   <span class="p">,</span> <span class="mf">0.1</span>   <span class="p">,</span> <span class="mf">0.7</span>   <span class="p">]</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.0666</span><span class="p">,</span> <span class="mf">0.2666</span><span class="p">,</span> <span class="mf">0.6666</span><span class="p">]]</span>
</pre></div>
</div>
<p>The entropy of this is</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">consensus_entropy</span>
<span class="gp">... </span><span class="p">[</span><span class="mf">0.8167</span><span class="p">,</span> <span class="mf">1.0521</span><span class="p">,</span> <span class="mf">1.0296</span><span class="p">,</span> <span class="mf">0.8018</span><span class="p">,</span> <span class="mf">0.8033</span><span class="p">]</span>
</pre></div>
</div>
<p>Even though the votes for the second instance are <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">2]</span></code>, since the classifiers are quite unsure, thus the consensus entropy is high. In this case, the query strategy would select the second example to be labelled by the Oracle.</p>
</div>
<div class="section" id="max-disagreement">
<h3>Max disagreement<a class="headerlink" href="#max-disagreement" title="Permalink to this headline">¶</a></h3>
<p>The disagreement measures so far take the actual <em>disagreement</em> into account in a weak way. Instead of this, it is possible to to measure each learner’s disagreement with the consensus probabilities and query the instance where the disagreement is largest for some learner. This is called <em>max disagreement sampling</em>. Continuing our example, if the vote probabilities for each learner and the consensus probabilities are given, we can calculate the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler divergence</a> of each learner to the consensus prediction and then for each instance, select the largest value.</p>
<div class="code python highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">learner_KL_div</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">entropy</span><span class="p">(</span><span class="n">vote_proba</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">],</span> <span class="n">qk</span><span class="o">=</span><span class="n">consensus_proba</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learner_KL_div</span>
<span class="gp">... </span><span class="p">[[</span><span class="mf">0.32631363</span><span class="p">,</span>  <span class="mf">0.80234647</span><span class="p">,</span>  <span class="mf">0.15685227</span><span class="p">],</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.27549995</span><span class="p">,</span>  <span class="mf">0.23005799</span><span class="p">,</span>  <span class="mf">0.69397192</span><span class="p">],</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.69314718</span><span class="p">,</span>  <span class="mf">0.34053564</span><span class="p">,</span>  <span class="mf">0.22380466</span><span class="p">],</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.04613903</span><span class="p">,</span>  <span class="mf">0.02914912</span><span class="p">,</span>  <span class="mf">0.15686827</span><span class="p">],</span>
<span class="gp">... </span> <span class="p">[</span><span class="mf">0.70556709</span><span class="p">,</span>  <span class="mf">0.40546511</span><span class="p">,</span>  <span class="mf">0.17201121</span><span class="p">]]</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_disagreement</span>
<span class="gp">... </span><span class="p">[</span><span class="mf">0.80234647</span><span class="p">,</span>  <span class="mf">0.69397192</span><span class="p">,</span>  <span class="mf">0.69314718</span><span class="p">,</span>  <span class="mf">0.15686827</span><span class="p">,</span>  <span class="mf">0.70556709</span><span class="p">]</span>
</pre></div>
</div>
<p>In this case, one of the learner highly disagrees with the others in the class of the first instance. Thus, the max disagreement sampling would choose this one to be labelled by the Oracle.</p>
</div>
</div>
<div class="section" id="disagreement-sampling-for-regressors">
<h2>Disagreement sampling for regressors<a class="headerlink" href="#disagreement-sampling-for-regressors" title="Permalink to this headline">¶</a></h2>
<p>Since regressors in general don’t provide a way to calculate prediction probabilities, disagreement measures for classifiers may not work with regressors. Despite of this, ensemble regression models can be always used in an active learning scenario, because the standard deviation of the predictions at a given point can be thought of as a measure of disagreement.</p>
<div class="section" id="standard-deviation-sampling">
<h3>Standard deviation sampling<a class="headerlink" href="#standard-deviation-sampling" title="Permalink to this headline">¶</a></h3>
<div class="figure align-center">
<img alt="../../_images/er-initial2.png" src="../../_images/er-initial2.png" />
</div>
<p>When a committee of regressors is available, uncertainty of predictions can be estimated by calculating the standard deviation of predictions. This is done by the <code class="docutils literal notranslate"><span class="pre">modAL.disagreement.max_std_sampling</span></code> function.</p>
</div>
</div>
<div class="section" id="disagreement-measures-in-action">
<h2>Disagreement measures in action<a class="headerlink" href="#disagreement-measures-in-action" title="Permalink to this headline">¶</a></h2>
<p>To visualize the disagreement measures, let’s consider a toy example! Suppose that we would like to learn these two objects:</p>
<div class="figure align-center">
<img alt="../../_images/dis-data.png" src="../../_images/dis-data.png" />
</div>
<p>We train two random forest classifiers:</p>
<div class="figure align-center">
<img alt="../../_images/dis-learners.png" src="../../_images/dis-learners.png" />
</div>
<p>The consensus predictions of these learners are</p>
<div class="figure align-center">
<img alt="../../_images/dis-consensus.png" src="../../_images/dis-consensus.png" />
</div>
<p>In this case, the disagreement measures from left to right are vote entropy, consensus entropy and max disagreement.</p>
<div class="figure align-center">
<img alt="../../_images/dis-measures.png" src="../../_images/dis-measures.png" />
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../examples/Pool-based-sampling.html" class="btn btn-neutral float-right" title="Pool-based sampling" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Uncertainty-sampling.html" class="btn btn-neutral" title="Uncertainty sampling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Tivadar Danka

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>